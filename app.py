import streamlit as st
import requests
import time
from datetime import datetime
import threading
import copy
import json
import random
import redis
import logging
import pickle
import streamlit.components.v1 as components

# --- 1. é¡µé¢é…ç½®å’Œå…¨å±€è®¾ç½® ---

st.set_page_config(
    page_title="RunningHub AI - æ™ºèƒ½å›¾ç‰‡ä¼˜åŒ–å·¥å…·",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é…ç½®æ—¥å¿—ï¼Œå‡å°‘å™ªéŸ³
logging.getLogger("tornado.access").setLevel(logging.ERROR)
logging.getLogger("tornado.application").setLevel(logging.ERROR)
logging.getLogger("tornado.general").setLevel(logging.ERROR)

# Redisé…ç½®
REDIS_HOST = 'redis-18743.c340.ap-northeast-2-1.ec2.redns.redis-cloud.com'
REDIS_PORT = 18743
REDIS_PASSWORD = "dBAPubXYReEwHaIvnvX0lvr3qIgtudCp"

# APIé…ç½®
API_KEY = "9394a5c6d9454cd2b31e24661dd11c3d"
WEBAPP_ID = "1947599512657453057"
NODE_INFO = [
    {"nodeId": "38", "fieldName": "image", "fieldValue": "placeholder.png", "description": "å›¾ç‰‡è¾“å…¥"},
    {"nodeId": "60", "fieldName": "text", "fieldValue": "8k, high quality, high detail", "description": "æ­£å‘æç¤ºè¯è¡¥å……"},
    {"nodeId": "4", "fieldName": "text", "fieldValue": "è‰²è°ƒè‰³ä¸½,è¿‡æ›,é™æ€,ç»†èŠ‚æ¨¡ç³Šä¸æ¸…,å­—å¹•,é£æ ¼,ä½œå“,ç”»ä½œ,ç”»é¢,é™æ­¢,æ•´ä½“å‘ç°,æœ€å·®è´¨é‡,ä½è´¨é‡,JPEGå‹ç¼©æ®‹ç•™,ä¸‘é™‹çš„,æ®‹ç¼ºçš„,å¤šä½™çš„æ‰‹æŒ‡,ç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨,ç”»å¾—ä¸å¥½çš„è„¸éƒ¨,ç•¸å½¢çš„,æ¯å®¹çš„,å½¢æ€ç•¸å½¢çš„è‚¢ä½“,æ‰‹æŒ‡èåˆ,é™æ­¢ä¸åŠ¨çš„ç”»é¢,æ‚²ä¹±çš„èƒŒæ™¯,ä¸‰æ¡è…¿,èƒŒæ™¯äººå¾ˆå¤š,å€’ç€èµ°", "description": "åå‘æç¤ºè¯"}
]

# ç³»ç»Ÿé…ç½®
MAX_GLOBAL_CONCURRENT = 10  
MAX_LOCAL_CONCURRENT = 3   
MAX_RETRIES = 3            
POLL_INTERVAL = 3          
MAX_POLL_COUNT = 300       
AUTO_REFRESH_INTERVAL = 6  # å‡å°‘åˆ°6ç§’ä»¥æé«˜å“åº”æ€§
DISPLAY_TIMEOUT_MINUTES = 3  
ACTUAL_TIMEOUT_MINUTES = 15  

# Redisé”®å
GLOBAL_TASK_QUEUE = "runninghub:task_queue"
GLOBAL_PROCESSING_SET = "runninghub:processing_tasks"
SESSION_DATA_PREFIX = "runninghub:session:"

# å¹¶å‘é™åˆ¶é”™è¯¯å…³é”®è¯
CONCURRENT_LIMIT_ERRORS = [
    "concurrent limit", "too many requests", "rate limit",
    "é˜Ÿåˆ—å·²æ»¡", "å¹¶å‘é™åˆ¶", "æœåŠ¡å¿™ç¢Œ", "CONCURRENT_LIMIT_EXCEEDED", "TOO_MANY_REQUESTS"
]

# --- 2. ä¼˜åŒ–CSSæ ·å¼å’ŒJavaScript ---

st.markdown("""
<style>
    .main { background-color: #f8f9fa; }
    .stButton>button {
        width: 100%; border-radius: 6px; height: 2.5em;
        background-color: #0066cc; color: white; font-weight: 500;
        transition: all 0.2s ease;
    }
    .stButton>button:hover { 
        background-color: #0052a3; 
        transform: translateY(-1px);
    }
    .stButton>button:active {
        transform: translateY(0);
        background-color: #004080;
    }
    .download-clicked {
        background-color: #28a745 !important;
        transform: scale(0.98);
    }
    .task-card {
        background: white; border-radius: 8px; padding: 1rem; margin: 0.5rem 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1); border-left: 4px solid #0066cc;
    }
    .success-badge { color: #28a745; font-weight: 600; }
    .error-badge { color: #dc3545; font-weight: 600; }
    .processing-badge { color: #fd7e14; font-weight: 600; }
    .queued-badge { color: #6f42c1; font-weight: 600; }
    .metric-box {
        background: white; padding: 0.8rem; border-radius: 6px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1); text-align: center; margin-bottom: 0.3rem;
    }
    .compact-info { font-size: 0.85em; color: #6c757d; margin: 0.2rem 0; }
    .real-time { 
        font-family: 'Courier New', monospace; 
        color: #495057; 
        font-weight: 500;
        background-color: #f8f9fa;
        padding: 2px 6px;
        border-radius: 3px;
    }
    .download-feedback {
        position: fixed;
        top: 20px;
        right: 20px;
        background: #28a745;
        color: white;
        padding: 10px 20px;
        border-radius: 5px;
        z-index: 1000;
        animation: slideIn 0.3s ease-out;
    }
    @keyframes slideIn {
        from { transform: translateX(100%); opacity: 0; }
        to { transform: translateX(0); opacity: 1; }
    }
</style>

<script>
// å®æ—¶æ—¶é—´æ›´æ–°
function updateElapsedTimes() {
    const timeElements = document.querySelectorAll('[data-start-time]');
    timeElements.forEach(element => {
        const startTime = parseFloat(element.getAttribute('data-start-time'));
        const displayTimeout = parseInt(element.getAttribute('data-display-timeout')) * 60;
        const now = Date.now() / 1000;
        const elapsed = now - startTime;
        
        const elapsedMinutes = Math.floor(elapsed / 60);
        const elapsedSeconds = Math.floor(elapsed % 60);
        
        let timeText = `â±ï¸ å·²ç”¨æ—¶ ${elapsedMinutes}:${elapsedSeconds.toString().padStart(2, '0')}`;
        
        if (elapsed < displayTimeout) {
            const remaining = Math.max(0, displayTimeout - elapsed);
            const remainingMinutes = Math.floor(remaining / 60);
            const remainingSeconds = Math.floor(remaining % 60);
            timeText += ` | é¢„è®¡å‰©ä½™ ${remainingMinutes}:${remainingSeconds.toString().padStart(2, '0')}`;
        } else {
            timeText += ' | å¤„ç†ä¸­...';
        }
        
        element.innerHTML = timeText;
    });
}

// ä¸‹è½½åé¦ˆ
function showDownloadFeedback() {
    const feedback = document.createElement('div');
    feedback.className = 'download-feedback';
    feedback.textContent = 'âœ… ä¸‹è½½å¼€å§‹ï¼';
    document.body.appendChild(feedback);
    
    setTimeout(() => {
        feedback.remove();
    }, 2000);
}

// é¡µé¢åŠ è½½å®Œæˆåå¯åŠ¨å®šæ—¶å™¨
document.addEventListener('DOMContentLoaded', function() {
    setInterval(updateElapsedTimes, 1000); // æ¯ç§’æ›´æ–°
});

// å¯¹äºåŠ¨æ€åŠ è½½çš„å†…å®¹ï¼Œä¹Ÿè¦å¯åŠ¨å®šæ—¶å™¨
setTimeout(() => {
    setInterval(updateElapsedTimes, 1000);
}, 1000);
</script>
""", unsafe_allow_html=True)

# --- 3. Redisè¿æ¥åˆå§‹åŒ–ï¼ˆä¼˜åŒ–ç¼“å­˜ï¼‰ ---

@st.cache_resource(ttl=300)
def init_redis_connection():
    """åˆå§‹åŒ–Redisè¿æ¥"""
    try:
        r = redis.Redis(
            host=REDIS_HOST, port=REDIS_PORT,
            decode_responses=False, username="default", password=REDIS_PASSWORD,
            socket_timeout=3, socket_connect_timeout=3,
            retry_on_timeout=True, health_check_interval=60
        )
        r.ping()
        return r, None
    except Exception as e:
        return None, f"Redisè¿æ¥å¤±è´¥: {str(e)}"

r, redis_error = init_redis_connection()

# --- 4. Session Stateç®¡ç† ---

def get_session_key():
    if 'session_id' not in st.session_state:
        st.session_state.session_id = f"s_{int(time.time())}_{random.randint(100, 999)}"
    return st.session_state.session_id

def save_session_data():
    """å¼‚æ­¥ä¿å­˜ä¼šè¯æ•°æ®"""
    if not r:
        return
    try:
        session_key = SESSION_DATA_PREFIX + get_session_key()
        session_data = {
            'tasks': [{'task_id': t.task_id, 'file_name': t.file_name, 'session_id': t.session_id,
                      'status': t.status, 'progress': t.progress, 'retry_count': t.retry_count}
                     for t in st.session_state.get('tasks', [])],
            'task_counter': st.session_state.get('task_counter', 0),
            'timestamp': time.time()
        }
        r.setex(session_key, 1800, pickle.dumps(session_data))
    except:
        pass

# åˆå§‹åŒ–Session State
if 'tasks' not in st.session_state:
    st.session_state.tasks = []
if 'task_counter' not in st.session_state:
    st.session_state.task_counter = 0
if 'file_uploader_key' not in st.session_state:
    st.session_state.file_uploader_key = 0
if 'upload_success' not in st.session_state:
    st.session_state.upload_success = False
if 'download_clicked' not in st.session_state:
    st.session_state.download_clicked = {}

# --- 5. ç²¾ç®€ä»»åŠ¡ç±» ---

class TaskItem:
    def __init__(self, task_id, file_data, file_name, session_id):
        self.task_id = task_id
        self.file_data = file_data
        self.file_name = file_name
        self.session_id = session_id
        self.status = "QUEUED"
        self.progress = 0
        self.result_data = None
        self.error_message = None
        self.api_task_id = None
        self.created_at = datetime.now()
        self.start_time = None
        self.elapsed_time = None
        self.retry_count = 0

    def to_dict(self):
        return {
            'task_id': self.task_id, 'file_name': self.file_name, 'session_id': self.session_id,
            'created_at': self.created_at.isoformat(), 'retry_count': self.retry_count
        }

# --- 6. æ ¸å¿ƒAPIå‡½æ•° ---

def is_concurrent_limit_error(error_msg):
    error_lower = error_msg.lower()
    return any(keyword in error_lower for keyword in CONCURRENT_LIMIT_ERRORS)

def upload_file(file_data, file_name, api_key):
    url = 'https://www.runninghub.cn/task/openapi/upload'
    files = {'file': (file_name, file_data)}
    data = {'apiKey': api_key, 'fileType': 'image'}
    response = requests.post(url, files=files, data=data, timeout=60)
    response.raise_for_status()
    result = response.json()
    if result.get("code") == 0:
        return result['data']['fileName']
    else:
        raise Exception(f"ä¸Šä¼ å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")

def run_task(api_key, webapp_id, node_info_list):
    url = 'https://www.runninghub.cn/task/openapi/ai-app/run'
    payload = {"apiKey": api_key, "webappId": webapp_id, "nodeInfoList": node_info_list}
    response = requests.post(url, headers={'Content-Type': 'application/json'}, 
                           json=payload, timeout=30)
    response.raise_for_status()
    result = response.json()
    if result.get("code") != 0:
        raise Exception(f"ä»»åŠ¡å‘èµ·å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
    return result['data']['taskId']

def get_task_status(api_key, task_id):
    url = 'https://www.runninghub.cn/task/openapi/status'
    response = requests.post(url, json={'apiKey': api_key, 'taskId': task_id}, timeout=10)
    response.raise_for_status()
    return response.json().get('data')

def fetch_task_output(api_key, task_id):
    url = 'https://www.runninghub.cn/task/openapi/outputs'
    response = requests.post(url, json={'apiKey': api_key, 'taskId': task_id}, timeout=30)
    response.raise_for_status()
    data = response.json()
    if data.get("code") == 0 and data.get("data"):
        file_url = data["data"][0].get("fileUrl")
        if file_url:
            return file_url
    raise Exception(f"è·å–ç»“æœå¤±è´¥: {data.get('msg', 'æœªæ‰¾åˆ°ç»“æœ')}")

def download_result_image(url):
    response = requests.get(url, stream=True, timeout=60)
    response.raise_for_status()
    return response.content

# --- 7. ä»»åŠ¡å¤„ç†é€»è¾‘ ---

def process_single_task(task, api_key, webapp_id, node_info):
    task.status = "PROCESSING"
    task.start_time = time.time()
    
    try:
        task.progress = 15
        uploaded_filename = upload_file(task.file_data, task.file_name, api_key)
        
        task.progress = 25
        node_info_list = copy.deepcopy(node_info)
        for node in node_info_list:
            if node["nodeId"] == "38":
                node["fieldValue"] = uploaded_filename
        
        task.progress = 35
        task.api_task_id = run_task(api_key, webapp_id, node_info_list)
        
        poll_count = 0
        while poll_count < MAX_POLL_COUNT:
            time.sleep(POLL_INTERVAL)
            poll_count += 1
            
            status = get_task_status(api_key, task.api_task_id)
            task.progress = min(90, 35 + (55 * poll_count / MAX_POLL_COUNT))
            
            if status == "SUCCESS":
                break
            elif status == "FAILED":
                raise Exception("APIä»»åŠ¡å¤„ç†å¤±è´¥")
            
            if poll_count % 20 == 0:
                save_session_data()
        
        if poll_count >= MAX_POLL_COUNT:
            raise Exception(f"ä»»åŠ¡è¶…æ—¶ (>{ACTUAL_TIMEOUT_MINUTES}åˆ†é’Ÿ)")
        
        task.progress = 95
        result_url = fetch_task_output(api_key, task.api_task_id)
        task.result_data = download_result_image(result_url)
        
        task.progress = 100
        task.status = "SUCCESS"
        task.elapsed_time = time.time() - task.start_time
        save_session_data()
        
    except Exception as e:
        error_msg = str(e)
        task.elapsed_time = time.time() - task.start_time if task.start_time else 0
        
        if (is_concurrent_limit_error(error_msg) and task.retry_count < MAX_RETRIES):
            task.retry_count += 1
            task.status = "QUEUED"
            task.progress = 0
            time.sleep((2 ** task.retry_count) + random.randint(1, 3))
            if r:
                queue_key = GLOBAL_TASK_QUEUE.encode()
                task_data = json.dumps(task.to_dict()).encode()
                r.rpush(queue_key, task_data)
        else:
            task.status = "FAILED"
            task.error_message = error_msg[:100]
            
        save_session_data()
    
    finally:
        if r:
            processing_key = GLOBAL_PROCESSING_SET.encode()
            r.srem(processing_key, str(task.task_id))

# --- 8. é˜Ÿåˆ—ç®¡ç† ---

@st.cache_data(ttl=2)
def get_queue_stats():
    if not r:
        return {'queued': 0, 'global_processing': 0, 'local_processing': 0}
    
    try:
        queue_key = GLOBAL_TASK_QUEUE.encode()
        processing_key = GLOBAL_PROCESSING_SET.encode()
        
        queued = r.llen(queue_key)
        global_processing = r.scard(processing_key)
        local_processing = sum(1 for t in st.session_state.tasks if t.status == "PROCESSING")
        
        return {'queued': queued, 'global_processing': global_processing, 'local_processing': local_processing}
    except:
        return {'queued': 0, 'global_processing': 0, 'local_processing': 0}

def start_new_tasks():
    if not r:
        return
    
    try:
        stats = get_queue_stats()
        available_slots = min(
            MAX_GLOBAL_CONCURRENT - stats['global_processing'],
            MAX_LOCAL_CONCURRENT - stats['local_processing']
        )
        
        if available_slots <= 0:
            return
            
        queue_key = GLOBAL_TASK_QUEUE.encode()
        processing_key = GLOBAL_PROCESSING_SET.encode()
        
        for _ in range(available_slots):
            task_data_bytes = r.lpop(queue_key)
            if not task_data_bytes:
                break
                
            task_data = json.loads(task_data_bytes.decode())
            task_id = task_data['task_id']
            
            local_task = next((t for t in st.session_state.tasks if t.task_id == task_id), None)
            
            if local_task and local_task.file_data:
                local_task.retry_count = task_data.get('retry_count', 0)
                r.sadd(processing_key, str(task_id))
                
                thread = threading.Thread(
                    target=process_single_task,
                    args=(local_task, API_KEY, WEBAPP_ID, NODE_INFO)
                )
                thread.daemon = True
                thread.start()
            else:
                r.rpush(queue_key, task_data_bytes)
                
    except:
        pass

# --- 9. ä¼˜åŒ–ä¸‹è½½æŒ‰é’®ç»„ä»¶ ---

def create_download_button(task):
    """åˆ›å»ºä¼˜åŒ–çš„ä¸‹è½½æŒ‰é’®"""
    file_size = len(task.result_data) / 1024  # KB
    button_key = f"download_{task.task_id}"
    
    # æ£€æŸ¥æ˜¯å¦åˆšåˆšç‚¹å‡»è¿‡
    clicked = st.session_state.download_clicked.get(task.task_id, False)
    if clicked:
        st.session_state.download_clicked[task.task_id] = False
        
        # æ˜¾ç¤ºå³æ—¶åé¦ˆ
        components.html("""
        <script>
            window.parent.postMessage({type: 'download_clicked'}, '*');
            if (typeof showDownloadFeedback === 'function') {
                showDownloadFeedback();
            }
        </script>
        """, height=0)
    
    # ä¸‹è½½æŒ‰é’®
    downloaded = st.download_button(
        label=f"ğŸ“¥ ä¸‹è½½ç»“æœ ({file_size:.1f}KB)",
        data=task.result_data,
        file_name=f"optimized_{task.file_name}",
        mime="image/png",
        key=button_key,
        use_container_width=True,
        help="ç‚¹å‡»ç«‹å³ä¸‹è½½ä¼˜åŒ–åçš„å›¾ç‰‡"
    )
    
    if downloaded:
        st.session_state.download_clicked[task.task_id] = True
        st.rerun()

# --- 10. ä¸»ç•Œé¢ ---

def main():
    st.title("ğŸ¨ RunningHub AI - æ™ºèƒ½å›¾ç‰‡ä¼˜åŒ–å·¥å…·")
    st.caption("é«˜æ•ˆå¤„ç† â€¢ å¿«é€Ÿå“åº” â€¢ å®æ—¶æ›´æ–°")
    
    st.info(f"â±ï¸ é¢„è®¡å¤„ç†æ—¶é—´: {DISPLAY_TIMEOUT_MINUTES}åˆ†é’Ÿ | ğŸ”„ åˆ·æ–°é—´éš”: {AUTO_REFRESH_INTERVAL}ç§’")
    st.divider()
    
    # ä¸»ç•Œé¢å¸ƒå±€
    left_col, right_col = st.columns([1.8, 3.2])
    
    # å·¦ä¾§ï¼šä¸Šä¼ å’ŒçŠ¶æ€
    with left_col:
        st.markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
        
        if st.session_state.upload_success:
            st.success("âœ… æ–‡ä»¶å·²æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—!")
            st.session_state.upload_success = False
        
        uploaded_files = st.file_uploader(
            "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
            type=['png', 'jpg', 'jpeg', 'webp'],
            accept_multiple_files=True,
            help="æ”¯æŒæ‰¹é‡ä¸Šä¼ ï¼Œè‡ªåŠ¨åŠ å…¥å…¨å±€é˜Ÿåˆ—",
            key=f"uploader_{st.session_state.file_uploader_key}"
        )
        
        if uploaded_files:
            if not r:
                st.error("âš ï¸ Redisè¿æ¥å¤±è´¥")
            else:
                with st.spinner(f'æ·»åŠ  {len(uploaded_files)} ä¸ªæ–‡ä»¶...'):
                    new_tasks = []
                    for file in uploaded_files:
                        st.session_state.task_counter += 1
                        task = TaskItem(
                            st.session_state.task_counter, file.getvalue(), 
                            file.name, get_session_key()
                        )
                        st.session_state.tasks.append(task)
                        new_tasks.append(task)
                
                try:
                    queue_key = GLOBAL_TASK_QUEUE.encode()
                    pipe = r.pipeline()
                    for task in new_tasks:
                        task_data = json.dumps(task.to_dict()).encode()
                        pipe.rpush(queue_key, task_data)
                    pipe.execute()
                    
                    save_session_data()
                    st.session_state.upload_success = True
                    st.session_state.file_uploader_key += 1
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"âŒ æ·»åŠ å¤±è´¥: {str(e)[:50]}...")
        
        st.divider()
        
        # çŠ¶æ€é¢æ¿
        with st.expander("ğŸ“Š ç³»ç»ŸçŠ¶æ€", expanded=True):
            stats = get_queue_stats()
            local_stats = {
                'success': sum(1 for t in st.session_state.tasks if t.status == "SUCCESS"),
                'failed': sum(1 for t in st.session_state.tasks if t.status == "FAILED"),
                'total': len(st.session_state.tasks)
            }
            
            c1, c2, c3 = st.columns(3)
            
            with c1:
                st.markdown(f'<div class="metric-box"><h4 style="margin:0;color:#0066cc">{stats["queued"]}</h4><p style="margin:0;font-size:11px">é˜Ÿåˆ—</p></div>', unsafe_allow_html=True)
                st.markdown(f'<div class="metric-box"><h4 style="margin:0;color:#28a745">{local_stats["success"]}</h4><p style="margin:0;font-size:11px">å®Œæˆ</p></div>', unsafe_allow_html=True)
            
            with c2:
                st.markdown(f'<div class="metric-box"><h4 style="margin:0;color:#6f42c1">{stats["global_processing"]}/{MAX_GLOBAL_CONCURRENT}</h4><p style="margin:0;font-size:11px">å…¨å±€</p></div>', unsafe_allow_html=True)
                st.markdown(f'<div class="metric-box"><h4 style="margin:0;color:#dc3545">{local_stats["failed"]}</h4><p style="margin:0;font-size:11px">å¤±è´¥</p></div>', unsafe_allow_html=True)
            
            with c3:
                st.markdown(f'<div class="metric-box"><h4 style="margin:0;color:#fd7e14">{stats["local_processing"]}/{MAX_LOCAL_CONCURRENT}</h4><p style="margin:0;font-size:11px">æœ¬é¡µ</p></div>', unsafe_allow_html=True)
                st.markdown(f'<div class="metric-box"><h4 style="margin:0;color:#6c757d">{local_stats["total"]}</h4><p style="margin:0;font-size:11px">æ€»æ•°</p></div>', unsafe_allow_html=True)
        
        # ç³»ç»Ÿä¿¡æ¯
        with st.expander("âš™ï¸ ç³»ç»Ÿä¿¡æ¯", expanded=False):
            st.text(f"Redis: {'âœ…è¿æ¥' if r else 'âŒæ–­å¼€'}")
            st.text(f"ä¼šè¯: {get_session_key()}")
            st.text(f"é…ç½®: {MAX_GLOBAL_CONCURRENT}å…¨å±€/{MAX_LOCAL_CONCURRENT}æœ¬åœ°å¹¶å‘")
    
    # å³ä¾§ï¼šä»»åŠ¡åˆ—è¡¨
    with right_col:
        st.markdown("### ğŸ“‹ ä»»åŠ¡åˆ—è¡¨")
        
        if not st.session_state.tasks:
            st.info("ğŸ’¡ æš‚æ— ä»»åŠ¡ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶å¼€å§‹å¤„ç†")
        else:
            start_new_tasks()
            
            # æ˜¾ç¤ºä»»åŠ¡
            for task in reversed(st.session_state.tasks):
                with st.container():
                    st.markdown('<div class="task-card">', unsafe_allow_html=True)
                    
                    # ä»»åŠ¡å¤´éƒ¨
                    col1, col2 = st.columns([4, 1])
                    
                    with col1:
                        st.markdown(f"**{task.file_name}** `#{task.task_id}`")
                        if task.retry_count > 0:
                            st.markdown(f'<div class="compact-info">ğŸ”„ é‡è¯• {task.retry_count}/{MAX_RETRIES}</div>', unsafe_allow_html=True)
                    
                    with col2:
                        if task.status == "SUCCESS":
                            st.markdown('<span class="success-badge">âœ… å®Œæˆ</span>', unsafe_allow_html=True)
                        elif task.status == "FAILED":
                            st.markdown('<span class="error-badge">âŒ å¤±è´¥</span>', unsafe_allow_html=True)
                        elif task.status == "PROCESSING":
                            st.markdown('<span class="processing-badge">âš¡ å¤„ç†ä¸­</span>', unsafe_allow_html=True)
                        else:
                            st.markdown('<span class="queued-badge">â³ é˜Ÿåˆ—ä¸­</span>', unsafe_allow_html=True)
                    
                    # è¿›åº¦å’Œå®æ—¶æ—¶é—´æ˜¾ç¤º
                    if task.status == "PROCESSING":
                        st.progress(task.progress / 100, text=f"è¿›åº¦: {int(task.progress)}%")
                        
                        if task.start_time:
                            # ä½¿ç”¨JavaScriptå®ç°å®æ—¶æ—¶é—´æ›´æ–°
                            st.markdown(f'''
                            <div class="compact-info real-time" 
                                 data-start-time="{task.start_time}" 
                                 data-display-timeout="{DISPLAY_TIMEOUT_MINUTES}">
                                â±ï¸ è®¡ç®—ä¸­...
                            </div>
                            ''', unsafe_allow_html=True)
                    
                    elif task.status == "QUEUED":
                        st.markdown('<div class="compact-info">â³ ç­‰å¾…å¤„ç†...</div>', unsafe_allow_html=True)
                    
                    # ç»“æœå¤„ç†
                    if task.status == "SUCCESS" and task.result_data:
                        elapsed_str = f"{int(task.elapsed_time//60)}:{int(task.elapsed_time%60):02d}"
                        st.success(f"ğŸ‰ å¤„ç†å®Œæˆ! ç”¨æ—¶: {elapsed_str}")
                        
                        # ä½¿ç”¨ä¼˜åŒ–çš„ä¸‹è½½æŒ‰é’®
                        create_download_button(task)
                    
                    elif task.status == "FAILED":
                        st.error(f"ğŸ’¥ å¤„ç†å¤±è´¥")
                        if task.error_message:
                            st.markdown(f'<div class="compact-info">é”™è¯¯: {task.error_message}</div>', unsafe_allow_html=True)
                    
                    st.markdown('</div>', unsafe_allow_html=True)
            
            st.divider()
            
            # æ“ä½œæŒ‰é’®
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºæœ¬é¡µ"):
                    st.session_state.tasks = []
                    st.session_state.download_clicked = {}
                    save_session_data()
                    st.rerun()
            
            with col2:
                if r and st.button("ğŸ”¥ æ¸…ç©ºå…¨å±€"):
                    try:
                        r.delete(GLOBAL_TASK_QUEUE.encode(), GLOBAL_PROCESSING_SET.encode())
                        st.session_state.tasks = []
                        st.session_state.download_clicked = {}
                        save_session_data()
                        st.success("âœ… å·²æ¸…ç©º")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ å¤±è´¥: {str(e)[:30]}...")
            
            with col3:
                if st.button("ğŸ’¾ ä¿å­˜æ•°æ®"):
                    save_session_data()
                    st.success("âœ… å·²ä¿å­˜")

    # é¡µè„š
    st.divider()
    st.markdown("""
    <div style='text-align: center; color: #6c757d; padding: 15px;'>
        <b>ğŸš€ RunningHub AI - å®æ—¶å“åº”ç‰ˆ</b><br>
        <small>å¿«é€Ÿä¸‹è½½ â€¢ å®æ—¶æ—¶é—´æ›´æ–° â€¢ å³æ—¶åé¦ˆ</small>
    </div>
    """, unsafe_allow_html=True)

# --- 11. åº”ç”¨å…¥å£ ---

if __name__ == "__main__":
    try:
        main()
        
        # ä¼˜åŒ–åˆ·æ–°é€»è¾‘
        has_active_tasks = any(t.status in ["PROCESSING", "QUEUED"] for t in st.session_state.tasks)
        
        if has_active_tasks:
            time.sleep(AUTO_REFRESH_INTERVAL)
            st.rerun()
            
    except Exception as e:
        error_str = str(e).lower()
        if not any(kw in error_str for kw in ['websocket', 'tornado', 'streamlit']):
            st.error(f"âš ï¸ ç³»ç»Ÿé”™è¯¯: {str(e)[:100]}...")
            st.info("ç³»ç»Ÿå°†è‡ªåŠ¨æ¢å¤...")
            time.sleep(5)
        st.rerun()
